{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the quality scores of reads *after* they are mapped\n",
    "\n",
    "Information about mapped reads is stored within the **S**equence **A**lignment **M**ap file format (SAM). Following the header, each line of a SAM file contains information about a single alignment*. Each line has eleven standardised, tab-separated, fields. See [here](https://en.wikipedia.org/wiki/SAM_(file_format) for a description of each field.\n",
    "\n",
    "Here, we want to explore how read quality varies *along* a region of the reference genome.\n",
    "\n",
    "\n",
    "*Note that since in some cases a single read can align multiple times, alignments are different than the number of reads\n",
    "\n",
    "Written by Jason A. Hendry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract alignments within region of interest\n",
    "\n",
    "We are working with *P.f.* amplicon data in this example. We will focus on the analysis on a single amplicon, *Kelch13*. In order to do this, we will extract only those alignments that fall within the *Kelch13* exon. This can be achieved using `samtools view`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\" # data directory\n",
    "bam_fn = \"BC01.sorted.bam\"  # BAM file containing the alignments of interest\n",
    "target_bed = \"KELCH13.exons.bed\"  # a BED file delineating region of interest\n",
    "output_sam_fn = \"BC01.K13.sam\"\n",
    "output_dir = \"outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"samtools view %s -L %s -o %s\" % (\n",
    "    os.path.join(data_dir, bam_fn),\n",
    "    os.path.join(data_dir, target_bed),\n",
    "    os.path.join(output_dir, output_sam_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Command: %s\" % cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows the samtools command we want to run. We can run this from python using an `os.system()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(output_dir) # before command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated the desired SAM file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = open(os.path.join(output_dir, output_sam_fn), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the SAM file is tab delineated, we can parse out fields with a split on tab\n",
    "sam.readline().split(\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the CIGAR string\n",
    "\n",
    "Our goal is to assign each quality score to a position in the genome. If the read was mapped in one continguous region, this would be easy: we could simply align the quality scores with the start position of the read mapping. However, typically there will be many deletions and insertions in the mapping. This is especially true for nanopore data. \n",
    "\n",
    "Information about the mapping, including information about insertions or deletions, is stored within the CIGAR string. Briefly, the CIGAR string indicates with a character whether there has been a match \"M\", an insertion \"I\", or a deletion \"D\"; as well as indicating whether the read has been 'clipped' (\"S\" or \"H\"). Clipping can occur if, for example, you have limited the the SAM file to reads only present in a particular region. After the character, an integer is given which indicating the length of match, insertion, or deletion. Some examples\n",
    "\n",
    "- 28M would indicate that there is a match of 28 bases\n",
    "    - The read and the reference sequence are the same length for this region\n",
    "- 10D would indicate that there is a *deletion* in the read of 10 bases\n",
    "    - So the read is *shorter* than the reference genome in this region\n",
    "- 2I would indicate that there is an *insertion* in the read of 2 bases\n",
    "    - So the read is *longer* than the reference genome in this region\n",
    "\n",
    "\n",
    "For complete details see [here](https://samtools.github.io/hts-specs/SAMv1.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = sam.readline().split(\"\\t\")\n",
    "start = int(alignment[3])\n",
    "cigar = alignment[5]\n",
    "quals = alignment[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we need to do is produce a vector of positions for each quality score, using the start position and cigar string. The basic approach is:\n",
    "\n",
    "- If there is a match, the positions increment one base at a time\n",
    "- If there is a insertion in the read, those positions in the read are *not* in the reference genome\n",
    "    - Give them an invalid value (-999)\n",
    "- If there is a deletion in the read, we pass\n",
    "    - We are effectively skipping positions\n",
    "- If there is a soft-clip, those positions in the read are *not* in the target region\n",
    "    - Give them an invalid value (-998)\n",
    "- If there is a hard-clip, we pass\n",
    "\n",
    "An important detail to note here is that all the alignments within the SAM file are represented with respect to the *forward* strand. Those reads that mapped to the reverse strand are reverse-complimented before being stored in the SAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "i = start\n",
    "tags = re.findall(\"\\d*[MIDSH]\", cigar)  # parse the cigar string into 'tags'\n",
    "for tag in tags:\n",
    "    n = int(tag[:-1]) # this is the integer value of the tag\n",
    "    m = tag[-1] # this is the 'm'ethod: M, D, I, S, H ...\n",
    "    if m == 'M':  # match\n",
    "        pos.extend(np.arange(i, i + n))\n",
    "    elif m == \"I\":  # insertion\n",
    "        pos.extend(np.repeat(-999, n))\n",
    "    elif m == \"D\":  # deletion\n",
    "        pass\n",
    "    elif m == \"S\":  # clip\n",
    "        pos.extend(np.repeat(-998, n))\n",
    "    elif m == \"H\":\n",
    "        pass\n",
    "    else:\n",
    "        Print(\"Tag %s not identified.\" % m)\n",
    "    i += n  # we have moved forward n positions\n",
    "pos = np.array(pos) # convert to an array at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of positions: %d\" % len(pos))\n",
    "print(\"Length of quality scores: %d\" % len(quals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now let's convert the quality scores to error probabilities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = np.array([ord(c) - 33 for c in quals])\n",
    "error_probs = 10 ** (qs / -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results for this read..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "ax.plot(pos[pos > 0], error_probs[pos > 0])\n",
    "ax.set_xlabel(\"Genomic Position\")\n",
    "ax.set_ylabel(\"Error Probability\")\n",
    "ax.set_title(\"Single-read error probabilities mapped to $K13$\", loc='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalising\n",
    "\n",
    "Now all we need to do is expand this to handle the complete SAM file. For this we will build some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_error_from_sam(sam_path):\n",
    "    \"\"\"\n",
    "    Extract error probabilities and their positions\n",
    "    from a SAM file\n",
    "    \n",
    "    params\n",
    "        sam_path : str\n",
    "            Path to SAM file.\n",
    "            \n",
    "    returns\n",
    "        positions : list of ndarray, int, shape(n_reads, )\n",
    "            List of numpy arrays. Each array\n",
    "            encodes positions of aligned bases\n",
    "            for a read. Note that -998 indicates clipped,\n",
    "            -999 indicates deletion.\n",
    "        error_probs : list of ndarray, float, shape(n_reads, )\n",
    "            List of numpy arrays. Each array\n",
    "            encodes error probabilities aligned bases\n",
    "            for a read.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Open SAM\n",
    "    with open(sam_path, \"r\") as sam:\n",
    "\n",
    "        # Prepare storage\n",
    "        positions = []\n",
    "        error_probs = []\n",
    "\n",
    "        for alignment in sam:\n",
    "            # Parse alignment & get relevant fields\n",
    "            fields = alignment.split(\"\\t\")\n",
    "            start = int(fields[3])\n",
    "            cigar = fields[5]\n",
    "            quals = fields[10]\n",
    "\n",
    "            # Compute\n",
    "            alignment_error_probs = calc_error_probabilities(quals)\n",
    "            alignment_positions = get_positions_from_cigar(start, cigar)\n",
    "\n",
    "            # Store\n",
    "            positions.append(alignment_positions)\n",
    "            error_probs.append(alignment_error_probs)\n",
    "            \n",
    "    return positions, error_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_probabilities(quals):\n",
    "    \"\"\"\n",
    "    Calculate error probabilities from\n",
    "    a string of ASCII characters `quals` that\n",
    "    encode error probabilities\n",
    "    \n",
    "    params\n",
    "        quals : str\n",
    "            Error probabilities encoded in ASCII.\n",
    "    \n",
    "    returns\n",
    "        error_probs : ndarray, float, shape(read_length, )\n",
    "            Error probabilities in a\n",
    "            numpy array.\n",
    "    \n",
    "    \"\"\"\n",
    "    qs = np.array([ord(c) for c in quals]) - 33\n",
    "    error_probs = 10 ** (qs / -10)\n",
    "    return error_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions_from_cigar(start, cigar):\n",
    "    \"\"\"\n",
    "    Get alignment positions for each base in a read\n",
    "    given a `start` position and a `cigar` string\n",
    "    \n",
    "    params\n",
    "        start : int\n",
    "            The start position of the aligment.\n",
    "        cigar : str\n",
    "            The CIGAR string for the alignment.\n",
    "    \n",
    "    returns\n",
    "        pos : ndarray, int, shape (read_length,)\n",
    "            A genomic position for each base in the\n",
    "            read.\n",
    "    \n",
    "    \"\"\"\n",
    "    pos = []\n",
    "    i = start\n",
    "    tags = re.findall(\"\\d*[MIDSH]\", cigar)  # parse the cigar string into 'tags'\n",
    "    \n",
    "    for tag in tags:\n",
    "        n = int(tag[:-1]) # this is the integer value of the tag\n",
    "        m = tag[-1] # this is the 'm'ethod: M, D, I, S, H ...\n",
    "        if m == 'M':  # match\n",
    "            pos.extend(np.arange(i, i + n))\n",
    "        elif m == \"I\":  # insertion\n",
    "            pos.extend(np.repeat(-999, n))\n",
    "        elif m == \"D\":  # deletion\n",
    "            pass\n",
    "        elif m == \"S\":  # clip\n",
    "            pos.extend(np.repeat(-998, n))\n",
    "        elif m == \"H\":\n",
    "            pass\n",
    "        else:\n",
    "            Print(\"Tag %s not identified.\" % m)\n",
    "        i += n  # we have moved forward n positions\n",
    "    \n",
    "    return np.array(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_path = os.path.join(output_dir, output_sam_fn)\n",
    "positions, error_probs = positional_error_from_sam(sam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of reads...\n",
    "len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munge and visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.concatenate(positions)\n",
    "error_probs = np.concatenate(error_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = positions > 0\n",
    "positions = positions[keep]\n",
    "error_probs = error_probs[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positions)\n",
    "# 776 thousand bases have a quality score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.DataFrame({\"position\": positions, \"error_prob\": error_probs})\n",
    "      .groupby(\"position\")\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"position\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # mean error probabilities at each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "ax.plot(df[\"position\"], df[\"error_prob\"])\n",
    "ax.set_xlabel(\"Genomic Position\")\n",
    "ax.set_ylabel(\"Error Probability\")\n",
    "ax.set_title(\"Mean Error Probability Across $Kelch13$\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like more error at one end.. less coverage there perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"coverage\"] = (pd.DataFrame({\"position\": positions, \"error_prob\": error_probs})\n",
    "                  .groupby(\"position\")\n",
    "                  .size()\n",
    "                  .values\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "ax.plot(df[\"position\"], df[\"error_prob\"])\n",
    "ax.set_xlabel(\"Genomic Position\")\n",
    "ax.set_ylabel(\"Error Probability\")\n",
    "ax.set_title(\"Mean Error Probability Across $Kelch13$\", loc=\"left\")\n",
    "\n",
    "axm = ax.twinx()\n",
    "axm.fill_between(x=df[\"position\"],\n",
    "                 y1=np.repeat(0, df.shape[0]),\n",
    "                 y2=df[\"coverage\"],\n",
    "                 color='darkgrey', alpha=0.5)\n",
    "axm.set_ylabel(\"Coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Result seems to be explain by a decline in coverage\n",
    "- Would be interesting to indicate primer positions and gene body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
